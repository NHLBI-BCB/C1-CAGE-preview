{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OP-WORKFLOW-CAGEscan-short-reads-v2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This document is an example of how to process a C1CAGE library with a Jupyter notebook from raw reads to single molecule count. All the steps are described in the [tutorial](https://github.com/Population-Transcriptomics/C1-CAGE-preview/blob/master/tutorial.md) section of this repository. In the following section we assume that:\n",
    "- you are familiar with python programming and jupyter (ipython notebook)\n",
    "- the softwares mentioned in the [prerequesite](https://github.com/Population-Transcriptomics/C1-CAGE-preview/blob/master/prerequisite.md) section are all installed and referenced in your PATH\n",
    "- you've already dowloaded the availabe [C1CAGE library](https://briefcase.riken.jp/public/HOSkQAul5gIANkcBn25PAJuWL3WpMERFuJD6C8JmjEgm) and extracted it in your curent directory\n",
    "- The reference genome is already indexed with bwa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our hands this notebook worked without trouble on a machine running Debian GNU/Linux 8. We noticed that the behavior of tagdust2 in single-end mode was different on Mac OSX. In short, the order of the reads1 is changed after extraction on Mac OSX which is a problem because syncpairs expect the order of reads1 and reads2 to be the same. One way to overcome this issueis sort reads1 and reads2 separately after the exctraction then syncpairs will work properly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import subprocess, os, csv, signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "remove_extension = lambda x: x.split('.')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declare the function that deals with inputs and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_args(read1, read2, ref_genome, output_folders):\n",
    "    r1_shortname = remove_extension(os.path.basename(read1))\n",
    "\n",
    "    args = {  \n",
    "        'r1_input': read1,\n",
    "        'r2_input': read2,\n",
    "        'ref_genome': ref_genome,\n",
    "    }\n",
    "    \n",
    "    output_paths = {folder: os.path.join('output', folder, r1_shortname) for folder in output_folders}\n",
    "    \n",
    "    return dict(args, **output_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the required softwares are not in the PATH you can manually set their location here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tagdust2_path = 'tagdust'\n",
    "bwa_path = 'bwa'\n",
    "samtools_path = 'samtools'\n",
    "paired_bam_to_bed12_path = 'pairedBamToBed12'\n",
    "umicountFP_path = 'umicountFP'\n",
    "syncpairs_path = 'syncpairs'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Path to the reference genome you want to align your reads against"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ref_genome = './GRCh38.fa'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "softwares = {    \n",
    "    'bwa': bwa_path,\n",
    "    'tagdust': tagdust2_path,\n",
    "    'syncpairs': syncpairs_path,\n",
    "    'samtools': samtools_path,\n",
    "    'pairedBamToBed12': paired_bam_to_bed12_path,\n",
    "    'umicountFP': umicountFP_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The name of the output folders for each command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_folders = ['tagdust_r1', 'unzip_r2', 'extracted_r1', 'extracted_r2', 'cleaned_reads', 'cleaned_r1', 'cleaned_r2', \n",
    "                  'r1_sai', 'r2_sai', 'sampe', 'sam_to_bam', 'genome_mapped',\n",
    "                  'properly_paired', 'cagescan_pairs', 'cagescan_fragments']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for folder in output_folders:\n",
    "    os.makedirs(os.path.join('output', folder))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The actual command to run. See the [tutorial](https://github.com/Population-Transcriptomics/C1-CAGE-preview/blob/master/tutorial.md) section for more details about each command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cmds = [\n",
    "    \n",
    "    '{tagdust} -t8 -o {tagdust_r1} -1 F:NNNNNNNN -2 S:TATAGGG -3 R:N {r1_input}',\n",
    "    \n",
    "    'gunzip -c {r2_input} > {unzip_r2}.fq',\n",
    "        \n",
    "    '{syncpairs} {tagdust_r1}.fq {unzip_r2}.fq {extracted_r1}.fq {extracted_r2}.fq',\n",
    "    \n",
    "    '{tagdust} -arch SimpleArchitecture.txt -ref hg38_rDNA.fa -o {cleaned_reads} {extracted_r1}.fq {extracted_r2}.fq',\n",
    "    \n",
    "    'cp {cleaned_reads}_READ1.fq {cleaned_r1}.fq',\n",
    "    \n",
    "    'cp {cleaned_reads}_READ2.fq {cleaned_r2}.fq',\n",
    "    \n",
    "    '{bwa} aln {ref_genome} {cleaned_r1}.fq > {r1_sai}.sai',\n",
    "    \n",
    "    '{bwa} aln {ref_genome} {cleaned_r2}.fq > {r2_sai}.sai',\n",
    "    \n",
    "    '{bwa} sampe -a 2000000 -c 0.00001 {ref_genome} {r1_sai}.sai {r2_sai}.sai {cleaned_r1}.fq {cleaned_r2}.fq > {sampe}.sam',\n",
    "    \n",
    "    '{samtools} view -bSo  {sam_to_bam}.bam {sampe}.sam',\n",
    "    \n",
    "    '{samtools} sort -n {sam_to_bam}.bam {genome_mapped}',\n",
    "    \n",
    "    '{samtools} view -f 0x0002 -F 0x0100 -bo {properly_paired}.bam {genome_mapped}.bam',\n",
    "    \n",
    "    '{pairedBamToBed12} -i {properly_paired}.bam > {cagescan_pairs}.bed',\n",
    "    \n",
    "    '{umicountFP} -f {cagescan_pairs}.bed > {cagescan_fragments}.bed'\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the reads. Here we assume that the reads are in the current directory, in a folder named following the MiSeq run id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "root, folders, files = os.walk('./150519_M00528_0125_000000000-ACUAB/').next()\n",
    "\n",
    "files = [f for f in files if not f.startswith('.')] #remove hidden files if there exist\n",
    "reads1 = sorted([os.path.join(root, f) for f in files if 'R1' in f])\n",
    "reads2 = sorted([os.path.join(root, f) for f in files if 'R2' in f])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the commands for all the pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for read1, read2 in zip(reads1, reads2):\n",
    "    args = get_args(read1, read2, ref_genome, output_folders)\n",
    "    args = dict(args, **softwares)\n",
    "    \n",
    "    for cmd in cmds:\n",
    "#         print cmd.format(**args)\n",
    "        subprocess.call(cmd.format(**args), preexec_fn=lambda: signal.signal(signal.SIGPIPE, signal.SIG_DFL), shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the level1 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "root, folders, files = os.walk('./output/genome_mapped/').next()\n",
    "files = [os.path.join(root, f) for f in files if f.endswith('bam')]\n",
    "level1 = 'python ./PromoterPipeline_20150516/level1.py -o output/mylevel1file.l1.osc.gz -f 0x40 --fingerprint {files}'.format(files=' '.join(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.call(level1, shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# root, folder, files = os.walk('output/tagdust_r1/').next()\n",
    "# logs = [f for f in files if f.endswith('logfile.txt')]\n",
    "# logs\n",
    "# with open(os.path.join(root, logs[0])) as t2_log:\n",
    "#     reader = csv.reader(t2_log, delimiter='\\t')\n",
    "#     rows = [row for row in reader]\n",
    "#     non_empty = [row for row in rows if row]\n",
    "#     spikes_rows = [row for row in non_empty if 'ERCC' in row[-1]]\n",
    "#     number_of_spikes = sum([int(row[1]) for row in spikes_rows])\n",
    "#     number_of_spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
